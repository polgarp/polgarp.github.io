---
title: "e20 Designing for AI "
categories:
  - Newsletter
tags:
  - Design leadership
  - 9am26
header:
  overlay_image: /assets/images/.jpg
  overlay_filter: rgba(255, 0, 0, 0.8)
  show_overlay_excerpt: false
---

{% include figure image_path="/assets/images/.jpg" alt=", generated with DiffusionBee" caption=", generated with DiffusionBee" %}

# ‚òï Designing for AI

I'm keep getting asked how to design for AI. Since the hype just keeps growing, seemingly everyone is either already working on an AI product (at the minimum wondering how to add ChatGPT to all the input fields) or expects to work on one in the very near future. Hence the interest in how to actually do it.

I wrote an article a couple of years ago ([**Designing AI products**]({% post_url 2017-09-22-Designing-AI-products %})), when machine learning started to catch up. The article more or less covered the then state-of-the-art and our understanding of the challenges. Working with AI tech more recently, plus all the advances in the field (generative AI systems especially) allows me to update some details here, especially what this all means for designers.

Three statements to start with - neither of these should be highly controversial:
1. AI is a new tech, just having it in a software doesn't imply it's valuable.
2. If you are not using AI tools today, you are missing out. 
3. Our design approach will need to adapt.



First point, AI is not magicAI is a tech and depending on the exact technique used, design needs to happen differently. But also, these are tech - for example comparable how databases changed the type of software we could design. Which also means designers need to have some level of understanding what these systems can do.

Ultimately, the best way to get into AI design is to play with it, this why using tools is important (the added increase in effectiveness is just an added bonus) Explore generative tools, try to get APi - this helps in understanding the material of design. Or maybe a more closer idea is mobile design - those who didn't had a touchscreen mobile (khm, iPhone), were missing out what these devices were capable of.





But also getting through the hype is a question. As of writing this, prompt engineering is all the rage, that is how to ask the right quesions from generative systems (ChatGPT, Midjourney etc) to get great results. Will this be important? 

Also, with generative AI most of the UX is centered around text boxes. Will this remain so? Maybe as long as generative is a feature rather than the root of new products.

Fundamental questions to think about
- Interaction model
- Solutions that were hard earlier, are now easy.
- Experiences that were fixed, can be more dynamic.
- How to design experiences with uncertain outcomes? Things are often good enough, do we accept 95% good enough rate?
- Prototyping is different. AI models might only uncover behavior once they are working, so showing Figma prototypes won't be cutting it - tighter collaboration with engineering and data science teams is desirable.


I won't even get it ethical (and legal) question, it seems like an unstable Jenga tower about to collapse.

So what does this mean to design teams and leaders? One thing is mentoring junior designers. Second is encouraging experimentation to better understand capabilities. Third is remember design principles.

II. Understanding AI Technology

* Explanation of AI technology in product design
* Types of AI in product design
* Advantages and disadvantages of using AI in product design

III. Principles of Designing Software Products with AI

* Principle of Transparency
* Principle of User-Centered Design
* Principle of Collaboration
* Principle of Diversity and Inclusion
* Principle of Ethical Considerations

### ü•§ To recap

> This is a post from my newsletter, **[9am26](https://polgarp.com/categories/newsletter/)**, subscribe here:
> {% include newsletter-signup.html %}

# üç™ Things to snack on

There is a lot of hype going on around AI, and it's sometimes tough to understands what matters and why. I found the [**The Algorithmic Bridge**](https://thealgorithmicbridge.substack.com/) newsletter by **Alberto Romero** quite helpful to follow trends, in details slightly above the technical level and a bit farther away from the hype arena.

To understand how to design with AI, designers should explore by creating new things with this tech, argues **Gus Baggermans** in [**Embracing AI as a material for design**](https://uxdesign.cc/embracing-ai-as-a-material-for-design-b2986f7af7ed). The article also gives some general guidelines: Play responsibly, Design for discoverability, Help people navigate the maze of possibilities, and Consider legal & ethical implications. 

[**Design for AI: What should people who design AI know?**](https://uxdesign.cc/design-for-ai-what-should-people-who-design-ai-know-761e78fdabb) is a tool and an attempt to define what design skills will be needed for creating systems with AI by **Hal Wuertz**. It provides some useful behaviors for the five skill categories it presents (Technical, Ethics, Collaboration, Strategy, and Interactions). The list of behaviors might also give ideas for what skills to learn or improve.

16 excellent principles and added context to learn more by **Lennart Zibruski** in [**UX of AI**](https://uxofai.com/). Some of the principles just show how designing for AI is not that different from designing any software ("Start with the user"), while others are quite specific ("Explain the results"). 

**Jo√´l van Bodegraven** focuses on anticipatory design (how systems will think ahead the users) in  [**Design principles for AI-driven UX**](https://uxdesign.cc/ai-driven-ux-design-7735bdefbffc), describing systems designed with AI as simply "smart". The article also gives 5 principles to get started: Smart design has a purpose, Smart design is an extension of human capabilities, smart design anticipates, smart design should humanise experiences, smart design is proactive.

Google published a bunch of great and insightful articles, starting with [**The UX of AI**](https://design.google/library/ux-ai/) by **Josh Lovejoy** which is a case study about the Clips camera. Three main points on how AI needs human-centered design: solutions need to address a real human need, the intelligence needs guidance, and building trust needs to be core.

One problem with current machine learning based systems is that sometimes it's unclear why they do something the way they do it. This is the explainability problem, as **Meg Kurdziolek** writes in  [**Explaining the Unexplainable: Explainable AI (XAI) for UX**](https://uxpamagazine.org/explaining-the-unexplainable-explainable-ai-xai-for-ux/). The article provides an overview on techniques data scientist use. More importantly also, on how this problem affects users, as most users won't have a good mental model on what's happening inside such a system.